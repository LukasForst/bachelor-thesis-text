\section{Solution value prediction}\label{sec:algorithm-value-prediction}

To have the most informed decisions while creating load balancing decisions,
algorithm creating these decisions needs to be able to estimate the impact of assigned resources to the development of the solution value of the job.
Therefore in time $t$ it needs to estimate value of the solution value function $v_{t+1}^{j}$.
The definition in section \ref{sec:formal-definition} describes this estimated impact as $^{r}\Delta_{t}^{j}$ variable.
The reward for improving solution value $S_{t}^{j}$ is then computed based on this $^{r}\Delta_{t}^{j}$ value.
This reward is then used when the load balancing decisions are being made to reflect the suitability of the current execution plan solution.

Unfortunately, 
it is practically impossible to predict the values exactly.
For instance, heuristics and metaheuristics optimization algorithms are usually stochastic 
and therefore there is \textbf{no guarantee} that they eventually find a better solution than the current one.
That said, 
the only thing that is guaranteed is that the solution value function of the job overtime period is monotonically non-increasing.
Empirically,
the convergence of the solution value towards an optimal solution has hyperbolic shape.
This assumption was made after the analysis of the runtime solution value data from the optimization algorithms described in section \ref{sec:optimization-algorithms-data}.
In addition, 
the script, which is able to visualize, the solution value function during the time was developed.
This Python script is part of the implementation and can be found in the \inlinecode{scripts} folder inside the root of the project.

Moreover, 
it is not possible to use the time as $x$ axis,
because it would not be possible to extract information about 
how adding more available performance will modify the predicted solution value function of the job.
For that reason,
it is better to use the number of iterations, that optimization algorithm performed,
instead of the time unit.

\subsection{Hyperbola time series fitting}
The generic equation for expressing the hyperbola function on the two-dimensional graph is the following.
\begin{equation}
    a + \dfrac{b}{x+c} = y
\end{equation}
Where $a,b,c$ are parameters and $x,y$ are axis values.
For usage in a computer algorithm,
it is better to transform the equation into the form, 
where there is no division.
Apart from the better performance in favor of multiplication\cite{LeFevre1999},
it is possible that the state when $x = -c$ occurs.
If there is the division,
the resulting value will be infinity,
which breaks the next algorithm iterations.

Instead,
it is better to use the following form, 
where there is no division and $0$, as a result, is not a problem for the following algorithm iterations.
\begin{equation}\label{eq:final-hyperbola-fc}
    ax + ac + b - yc = yx
\end{equation}

Since the solution value prediction should be computed as fast as possible,
it was decided to use the mathematics optimization approach transforming the problem into non-linear least squares problem.

Non-linear least squares problems are often solved by the algorithms based on iterative estimate improvement. 
The example of these algorithms is the Gauss-Newton algorithm\cite{gratton2007approximate} 
and the Levenberg–Marquardt algorithm\cite{marquardt1963algorithm}.

\noindent % because it creates weird spacing
The second mentioned non-linear algorithm is more robust than the Gauss-Newton, 
because of the Marquardt parameter\cite{marquardt1963algorithm},
which means that in many cases it finds a solution even if it starts very far off the final minimum.

Using the Levenberg–Marquardt algorithm means, 
that it is necessary to know the derivation of the function, 
the algorithm is trying to fit in.
Derivation of the used function \ref{eq:final-hyperbola-fc} is then following.
\begin{equation}\label{eq:final-hyperbola-fd}
    f'(x) = (c+x, 1, a-y)
\end{equation}

As the target values, are used $x \cdot y$.
As the parameters, that Levenberg–Marquardt algorithm is trying to fit in are used $a,b,c$.